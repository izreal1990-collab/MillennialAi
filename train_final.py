"""
MillennialAI Complete Training System
llama3:8b + TRM Layer Injection ONLY

Single Model Architecture:
- Base: llama3:8b (8 billion parameters)
- Enhancement: TRM temporal reasoning injection
- Training: Fine-tune TRM on workspace knowledge  
- Output: Complete production MillennialAI

RTX 5060 Ti Optimized
November 6, 2025
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from pathlib import Path
import json
import logging
import time
import requests
import subprocess
from datetime import datetime
from typing import Dict, List, Optional, Any
from tqdm import tqdm

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Find workspace
def find_workspace() -> Path:
    if (Path.cwd() / "millennial_ai").exists():
        return Path.cwd()
    paths = [
        Path(r"C:\Users\jblan\workspace\MillennialAi"),
        Path.home() / "workspace" / "MillennialAi",
    ]
    for p in paths:
        if p.exists() and (p / "millennial_ai").exists():
            return p
    raise FileNotFoundError("Workspace not found")

PROJECT_ROOT = find_workspace()
sys.path.insert(0, str(PROJECT_ROOT))
logger.info(f"ðŸ“ Workspace: {PROJECT_ROOT}")

# Import
try:
    from millennial_ai.config.config import HybridConfig
    from real_brain import RealThinkingBrain
    from hybrid_brain import HybridRevolutionaryBrain, OllamaIntegration
    logger.info("âœ… Components loaded")
except ImportError as e:
    logger.error(f"âŒ Import failed: {e}")
    sys.exit(1)

try:
    import faiss
    FAISS_OK = True
except:
    FAISS_OK = False


class Ollama:
    """llama3:8b management"""
    
    def __init__(self):
        self.model = "llama3:8b"
        self.url = "http://localhost:11434"
    
    def is_running(self) -> bool:
        try:
            return requests.get(f"{self.url}/api/tags", timeout=5).status_code == 200
        except:
            return False
    
    def start(self) -> bool:
        if self.is_running():
            logger.info("âœ… Ollama running")
            return True
        logger.info("ðŸš€ Starting Ollama...")
        try:
            subprocess.Popen(
                ["ollama", "serve"],
                creationflags=subprocess.CREATE_NEW_CONSOLE if os.name == 'nt' else 0,
                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )
            for _ in range(10):
                time.sleep(1)
                if self.is_running():
                    logger.info("âœ… Ollama started")
                    return True
        except:
            logger.error("âŒ Install Ollama: https://ollama.com")
        return False
    
    def pull(self) -> bool:
        try:
            resp = requests.get(f"{self.url}/api/tags").json()
            if any(m['name'] == self.model for m in resp.get('models', [])):
                logger.info(f"âœ… {self.model} ready")
                return True
            logger.info(f"ðŸ“¥ Pulling {self.model}...")
            result = subprocess.run(["ollama", "pull", self.model], 
                                  capture_output=True, timeout=600)
            return result.returncode == 0
        except:
            return False
    
    def setup(self) -> bool:
        return self.start() and self.pull()


def load_knowledge(workspace: Path) -> List[str]:
    """Load workspace documents"""
    docs = []
    for pattern in ['*.md', '*.txt']:
        for file in workspace.rglob(pattern):
            if any(x in str(file) for x in ['.git', 'node_modules', '__pycache__', 
                                             '.gradle', 'sonar', 'android-monitor']):
                continue
            try:
                text = file.read_text(encoding='utf-8', errors='ignore')
                if len(text) > 100:
                    docs.append(text)
            except:
                pass
    logger.info(f"ðŸ“š Loaded {len(docs)} documents")
    return docs


def train_trm(brain: RealThinkingBrain, documents: List[str], epochs: int, save_dir: Path):
    """Train TRM on knowledge"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    brain.to(device)
    
    optimizer = optim.AdamW(brain.parameters(), lr=1e-4, weight_decay=0.01)
    logger.info(f"ðŸš€ Training {epochs} epochs on {device}")
    
    for epoch in range(epochs):
        logger.info(f"\nEpoch {epoch+1}/{epochs}")
        total_loss = 0
        
        for doc in tqdm(documents, desc="Training"):
            # Process chunks
            for i in range(0, len(doc), 256):
                chunk = doc[i:i+512]
                if len(chunk) < 50:
                    continue
                
                # Encode
                enc = [ord(c) % 256 for c in chunk[:50].ljust(50)]
                tensor = torch.tensor([enc], dtype=torch.float32).to(device)
                tensor = tensor.unsqueeze(-1).expand(1, 50, 768)
                
                # Train
                optimizer.zero_grad()
                result = brain.forward(tensor)
                
                # Loss: optimize for complexity and convergence
                loss = (result['complexity_score'] - 1.5) ** 2
                loss = loss + 0.1 * result['output'].abs().mean()
                
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
        
        avg_loss = total_loss / len(documents)
        logger.info(f"Loss: {avg_loss:.4f}")
        
        # Save
        checkpoint = {
            'epoch': epoch+1,
            'brain': brain.state_dict(),
            'optimizer': optimizer.state_dict(),
            'loss': avg_loss
        }
        torch.save(checkpoint, save_dir / f"checkpoint_epoch_{epoch+1}.pt")
        torch.save(checkpoint, save_dir / "millennialai_final.pt")
    
    logger.info("ðŸŽ‰ Training complete")


def create_vectors(brain: RealThinkingBrain, documents: List[str], save_dir: Path):
    """Create FAISS database"""
    if not FAISS_OK:
        return
    
    logger.info("ðŸ” Creating vectors...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    brain.to(device).eval()
    
    embeddings = []
    with torch.no_grad():
        for doc in tqdm(documents[:1000], desc="Embeddings"):
            enc = [ord(c) % 256 for c in doc[:50].ljust(50)]
            tensor = torch.tensor([enc], dtype=torch.float32).to(device)
            tensor = tensor.unsqueeze(-1).expand(1, 50, 768)
            result = brain.forward(tensor)
            embeddings.append(result['output'].mean(dim=1).cpu().numpy()[0])
    
    # Save
    emb_array = torch.tensor(embeddings)
    torch.save(emb_array, save_dir / "embeddings.pt")
    
    # FAISS
    emb_np = emb_array.numpy().astype('float32')
    faiss.normalize_L2(emb_np)
    index = faiss.IndexFlatIP(emb_np.shape[1])
    index.add(emb_np)
    faiss.write_index(index, str(save_dir / "vectors.faiss"))
    
    logger.info(f"âœ… {index.ntotal} vectors created")


def main():
    print("="*80)
    print("ðŸš€ MILLENNIALAI - COMPLETE TRAINING")
    print("ðŸ¦™ llama3:8b + TRM Layer Injection")
    print("="*80)
    
    # Setup llama3:8b
    ollama = Ollama()
    if not ollama.setup():
        logger.error("âŒ Ollama setup failed")
        return
    
    # Load knowledge
    docs = load_knowledge(PROJECT_ROOT)
    if not docs:
        logger.error("âŒ No documents")
        return
    
    # Initialize
    brain = RealThinkingBrain(hidden_size=768, max_depth=8)
    hybrid = HybridRevolutionaryBrain(hidden_size=768, max_depth=8)
    
    # Train
    save_dir = PROJECT_ROOT / "models"
    save_dir.mkdir(exist_ok=True)
    
    train_trm(brain, docs, epochs=5, save_dir=save_dir)
    create_vectors(brain, docs, save_dir=save_dir)
    
    # Metadata
    metadata = {
        'date': datetime.now().isoformat(),
        'model': 'llama3:8b',
        'documents': len(docs),
        'trm_parameters': sum(p.numel() for p in brain.parameters()),
        'components': ['llama3:8b', 'TRM', 'RealThinkingBrain', 'HybridBrain', 'FAISS']
    }
    
    with open(save_dir / "millennialai_info.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print("\n" + "="*80)
    print("âœ… MILLENNIALAI COMPLETE!")
    print("="*80)
    print(f"\nðŸ“¦ {save_dir}/")
    print("   - millennialai_final.pt")
    print("   - checkpoint_epoch_*.pt")
    print("   - embeddings.pt")
    print("   - vectors.faiss")
    print("   - millennialai_info.json")
    print("\nðŸš€ Ready for deployment!\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  Stopped")
    except Exception as e:
        logger.error(f"\nâŒ Error: {e}", exc_info=True)
